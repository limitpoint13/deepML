{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "checked-compensation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "minimal-person",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "alert-addition",
   "metadata": {},
   "outputs": [],
   "source": [
    "#z_train: flattened version of x_train\n",
    "z_train = [list(np.reshape(x_train_, (np.product(x_train_.shape)))) + [y_train_] for x_train_,y_train_ in zip(x_train, y_train)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "central-seminar",
   "metadata": {},
   "outputs": [],
   "source": [
    "#z_test: flattened version of x_test\n",
    "z_test = [list(np.reshape(x_test_, (np.product(x_test_.shape)))) + [y_test_] for x_test_,y_test_ in zip(x_test, y_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "substantial-proof",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "architectural-ecology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAM/klEQVR4nO3db4hc9b3H8c+n2iAmfRDNEoINNzEGjVxsWoZYqBYv0aA+MFZBGqGkKE0FhRQqVPRBxSfK5balkUtlew1NL73WQisGCbexsSoFCW5kr4nGGqsJzZo/E6LUKBjdfO+DPSlr3DmzmTkzZ3a/7xcMM3O+5+z5cvSTM3N+M/NzRAjA7PeFuhsA0B+EHUiCsANJEHYgCcIOJHFuP3e2YMGCWLJkST93CaSyf/9+HTt2zFPVugq77esl/VzSOZL+KyIeKVt/yZIlGhkZ6WaXAEo0Go2WtY5fxts+R9J/SrpB0uWS1tm+vNO/B6C3unnPvkrSWxHxdkSclPRbSWuraQtA1boJ+0WS/j7p+cFi2WfY3mB7xPZIs9nsYncAutHzq/ERMRwRjYhoDA0N9Xp3AFroJuxjkhZPev7lYhmAAdRN2F+WtNz2UttzJH1b0tZq2gJQtY6H3iLiU9v3SPqjJobeNkfEa5V1BqBSXY2zR8Q2Sdsq6gVAD/FxWSAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5LoahZXYJDt3bu3Ze3aa68t3XZ0dLS0PjQ01ElLteoq7Lb3S/pA0rikTyOiUUVTAKpXxZn93yLiWAV/B0AP8Z4dSKLbsIek7bZ32d4w1Qq2N9gesT3SbDa73B2ATnUb9qsi4muSbpB0t+1vnrlCRAxHRCMiGjPxogYwW3QV9ogYK+6PSnpK0qoqmgJQvY7Dbnuu7S+dfixpjaQ9VTUGoFrdXI1fKOkp26f/zv9ExP9W0lUP7Nu3r7T+3nvvldZXreJFy0yzc+fOlrXVq1f3sZPB0HHYI+JtSV+psBcAPcTQG5AEYQeSIOxAEoQdSIKwA0mk+Yrrjh07SutvvPFGaZ2ht8ETEaX1suHWN998s+p2Bh5ndiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IIs04+6ZNm0rra9as6VMnqMqJEydK6w8//HDL2saNG0u3nY2/qsSZHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSSDPOPj4+XncLqNhdd93V8bYrVqyosJOZgTM7kARhB5Ig7EAShB1IgrADSRB2IAnCDiQxa8bZ33333dL62NhYnzpBvxw/frzjba+77roKO5kZ2p7ZbW+2fdT2nknLLrD9rO19xf383rYJoFvTeRn/K0nXn7HsPkk7ImK5pB3FcwADrG3YI+JFSWe+XloraUvxeIukm6ttC0DVOr1AtzAiDhWPD0ta2GpF2xtsj9geaTabHe4OQLe6vhofE7PrtZxhLyKGI6IREY3Z+CN+wEzRadiP2F4kScX90epaAtALnYZ9q6T1xeP1kp6uph0AvdJ2nN32E5KukbTA9kFJP5b0iKTf2b5T0gFJt/WyyenYvn17af2jjz7qUyeoyocfflha3717d8d/+8ILL+x425mqbdgjYl2L0uqKewHQQ3xcFkiCsANJEHYgCcIOJEHYgSRmzVdc9+zZ036lEitXrqymEVTmgQceKK23+1rzFVdc0bI2Z86cjnqayTizA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EASs2acvVtXXnll3S3MSB9//HFpfdeuXS1rw8PDpds++eSTHfV02qZNm1rWzjvvvK7+9kzEmR1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkmCcvfD+++/Xtu9238s+depUaf2FF15oWXvnnXdKtz158mRp/dFHHy2tj4+Pl9bnzp3bsrZmzZrSbduNhX/yySel9RUrVpTWs+HMDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJzJpx9vPPP7+0bru0ftNNN5XWL7300rPuabpeeuml0npElNbPPbf1f8Z58+aVbtvue/z33ntvaf3qq68urZf9Hn/ZGLwkLV68uLTebkrnoaGh0no2bc/stjfbPmp7z6RlD9oesz1a3G7sbZsAujWdl/G/knT9FMt/FhEri9u2atsCULW2YY+IFyUd70MvAHqomwt099h+tXiZP7/VSrY32B6xPdJsNrvYHYBudBr2X0haJmmlpEOSftJqxYgYjohGRDS4YALUp6OwR8SRiBiPiFOSfilpVbVtAahaR2G3vWjS029J6m6+ZAA913ac3fYTkq6RtMD2QUk/lnSN7ZWSQtJ+Sd/vXYvT89BDD5XWly1bVlp//vnnK+zm7Cxfvry0fvvtt5fWL7nkkpa1pUuXdtRTP2zbVj6Ic/jw4dL6ZZddVmU7s17bsEfEuikWP96DXgD0EB+XBZIg7EAShB1IgrADSRB2IIlZ8xXXdtavX99VHdV75plnutr+jjvuqKiTHDizA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EASacbZMfvccsstdbcwo3BmB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgST4PjsGVkSU1g8cOFBav/jii6tsZ8Zre2a3vdj2n22/bvs12xuL5RfYftb2vuJ+fu/bBdCp6byM/1TSDyPicklfl3S37csl3SdpR0Qsl7SjeA5gQLUNe0QciohXiscfSNor6SJJayVtKVbbIunmHvUIoAJndYHO9hJJX5W0U9LCiDhUlA5LWthimw22R2yPNJvNbnoF0IVph932PEm/l/SDiPjH5FpMXEmZ8mpKRAxHRCMiGkNDQ101C6Bz0wq77S9qIui/iYg/FIuP2F5U1BdJOtqbFgFUYTpX4y3pcUl7I+Knk0pbJZ2e53i9pKerbw+Z2S69nTp1qvSGz5rOOPs3JH1H0m7bo8Wy+yU9Iul3tu+UdEDSbT3pEEAl2oY9Iv4iyS3Kq6ttB0Cv8HFZIAnCDiRB2IEkCDuQBGEHkuArrpixnnvuudL66tUMFk3GmR1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkmCcHQOr3U9J4+xwZgeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJBhnR21uvfXW0vpjjz3Wp05y4MwOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0m0HWe3vVjSryUtlBSShiPi57YflPQ9Sc1i1fsjYluvGsXs0+533ZljvVrT+VDNp5J+GBGv2P6SpF22ny1qP4uI/+hdewCqMp352Q9JOlQ8/sD2XkkX9boxANU6q/fstpdI+qqkncWie2y/anuz7fktttlge8T2SLPZnGoVAH0w7bDbnifp95J+EBH/kPQLScskrdTEmf8nU20XEcMR0YiIxtDQUPcdA+jItMJu+4uaCPpvIuIPkhQRRyJiPCJOSfqlpFW9axNAt9qG3bYlPS5pb0T8dNLyRZNW+5akPdW3B6Aq07ka/w1J35G02/Zosex+Setsr9TEcNx+Sd/vQX8AKjKdq/F/keQpSoypAzMIn6ADkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4k4Yjo387spqQDkxYtkHSsbw2cnUHtbVD7kuitU1X29i8RMeXvv/U17J/buT0SEY3aGigxqL0Nal8SvXWqX73xMh5IgrADSdQd9uGa919mUHsb1L4keutUX3qr9T07gP6p+8wOoE8IO5BELWG3fb3tv9p+y/Z9dfTQiu39tnfbHrU9UnMvm20ftb1n0rILbD9re19xP+UcezX19qDtseLYjdq+sabeFtv+s+3Xbb9me2OxvNZjV9JXX45b39+z2z5H0puSrpN0UNLLktZFxOt9baQF2/slNSKi9g9g2P6mpBOSfh0R/1os+3dJxyPikeIfyvkR8aMB6e1BSSfqnsa7mK1o0eRpxiXdLOm7qvHYlfR1m/pw3Oo4s6+S9FZEvB0RJyX9VtLaGvoYeBHxoqTjZyxeK2lL8XiLJv5n6bsWvQ2EiDgUEa8Ujz+QdHqa8VqPXUlffVFH2C+S9PdJzw9qsOZ7D0nbbe+yvaHuZqawMCIOFY8PS1pYZzNTaDuNdz+dMc34wBy7TqY/7xYX6D7vqoj4mqQbJN1dvFwdSDHxHmyQxk6nNY13v0wxzfg/1XnsOp3+vFt1hH1M0uJJz79cLBsIETFW3B+V9JQGbyrqI6dn0C3uj9bczz8N0jTeU00zrgE4dnVOf15H2F+WtNz2UttzJH1b0tYa+vgc23OLCyeyPVfSGg3eVNRbJa0vHq+X9HSNvXzGoEzj3WqacdV87Gqf/jwi+n6TdKMmrsj/TdIDdfTQoq+LJf1fcXut7t4kPaGJl3WfaOLaxp2SLpS0Q9I+SX+SdMEA9fbfknZLelUTwVpUU29XaeIl+quSRovbjXUfu5K++nLc+LgskAQX6IAkCDuQBGEHkiDsQBKEHUiCsANJEHYgif8HGYkDm0v4XQUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_index = 2\n",
    "print(y_train[image_index])\n",
    "plt.imshow(x_train[image_index], cmap='Greys')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "pressed-compatibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dooheon: We may change the type of questions. In that case, func:'finde_best_split' should be changed as well.\n",
    "\n",
    "class Question:\n",
    "    \"\"\"A Question is used to partition a dataset.\n",
    "    This class just records a 'pixcel index' (index in [0,28^2-1]) and 'threshold'. \n",
    "    The 'test' method is used to compare the threshold of the pixel's value in the sample \n",
    "    to the threshold stored in the question. \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, index_pixcel, threshold):\n",
    "        self.index_pixcel = index_pixcel\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def test(self, sample):\n",
    "        # sample: list-like, size 28^2 or 28^2+1 (when label is appended)\n",
    "        val = sample[self.index_pixcel]\n",
    "        return val >= self.threshold\n",
    "        \n",
    "    def __repr__(self):\n",
    "        # This is just a helper method to print\n",
    "        # the question in a readable format.\n",
    "        return \"Is %s-th pixcel >= %s?\" % (self.index_pixcel, str(self.threshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "duplicate-platform",
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition(samples, question):\n",
    "    \"\"\"\n",
    "    Partitions samples.\n",
    "    For each sample in the samples, check if it passes the question. If\n",
    "    so, add it to 'true samples', otherwise, add it to 'false samples'.\n",
    "    \"\"\"\n",
    "    true_samples, false_samples = [], []\n",
    "    for sample in samples:\n",
    "        if question.test(sample):\n",
    "            true_samples.append(sample)\n",
    "        else:\n",
    "            false_samples.append(sample)\n",
    "    return true_samples, false_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "headed-hypothesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distribution(samples):\n",
    "    \"\"\"returns the distribution (counting) of the number of each label in the samples.\"\"\"\n",
    "    distribution = {}  # a dictionary of label -> count.\n",
    "    for sample in samples:\n",
    "        # in our dataset format, the label is always the last column\n",
    "        label = sample[-1]\n",
    "        distribution.setdefault(str(label), 0)\n",
    "        distribution[str(label)] += 1\n",
    "    return distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "valued-exposure",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini_index(samples):\n",
    "    dist = distribution(samples)\n",
    "    gini = -1.0\n",
    "    for lbl in dist:\n",
    "        prob_of_lbl = dist[lbl] / float(len(samples))\n",
    "        gini -= prob_of_lbl**2\n",
    "    return gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "hungry-order",
   "metadata": {},
   "outputs": [],
   "source": [
    "def info_gain(left, right, current_uncertainty):\n",
    "    \"\"\"Information Gain.\n",
    "    The uncertainty of the starting node, minus the weighted impurity of\n",
    "    two child nodes.\n",
    "    \"\"\"\n",
    "    p = float(len(left)) / (len(left) + len(right))\n",
    "    information_gain = current_uncertainty - p * gini_index(left) - (1 - p) * gini_index(right)\n",
    "    return information_gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "expressed-costs",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_question(samples):\n",
    "    \"\"\"\n",
    "    Find the best question to ask among a selected set of questions\n",
    "    and calculate the information gain.\n",
    "    \"\"\"\n",
    "    best_gain = 0  # keep track of the best information gain\n",
    "    best_question = None  # keep track of the feature / value that produced it\n",
    "    current_uncertainty = gini_index(samples)\n",
    "    n_features = len(samples[0]) - 1  # number of columns\n",
    "\n",
    "    for col in range(n_features):  # for each feature\n",
    "        values = sorted(set([row[col] for row in samples]))\n",
    "        values_used = []\n",
    "        prev_val = -1\n",
    "        for val in values:  # for each value\n",
    "            if val < prev_val + 5:\n",
    "                continue # The resolution of the question is 5\n",
    "            prev_val = val\n",
    "            question = Question(col, val)\n",
    "\n",
    "            # try questionting the dataset\n",
    "            true_samples, false_samples = partition(samples, question)\n",
    "\n",
    "            # Skip this question if it doesn't divide the\n",
    "            # dataset.\n",
    "            if len(true_samples) == 0 or len(false_samples) == 0:\n",
    "                continue\n",
    "\n",
    "            # Calculate the information gain from this question\n",
    "            gain = info_gain(true_samples, false_samples, current_uncertainty)\n",
    "\n",
    "            # You actually can use '>' instead of '>=' here\n",
    "            # but I wanted the tree to look a certain way for our\n",
    "            # toy dataset.\n",
    "            if gain >= best_gain:\n",
    "                best_gain, best_question = gain, question\n",
    "        \n",
    "    return best_gain, best_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dried-outside",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Leaf:\n",
    "    \"\"\"A Leaf node classifies data.\n",
    "    This holds a dictionary of class (e.g., \"Apple\") -> number of times\n",
    "    it appears in the samples from the training data that reach this leaf.\n",
    "    \"\"\"\n",
    "    def __init__(self, samples):\n",
    "        self.predictions = distribution(samples)\n",
    "    def __repr__(self):\n",
    "        output = ''\n",
    "        for lbl in self.predictions:\n",
    "            output += '%s: %s\\n'%(lbl, self.predictions[lbl])\n",
    "        return output        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "metallic-squad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decision_Node:\n",
    "    \"\"\"A Decision Node asks a question.\n",
    "    This holds a reference to the question, and to the two child nodes.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 question,\n",
    "                 true_node,\n",
    "                 false_node):\n",
    "        self.question = question\n",
    "        self.true_node = true_node\n",
    "        self.false_node = false_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "swedish-wilderness",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tree(samples_train):\n",
    "    \"\"\"\n",
    "    Builds the tree. Returns the top node, which can be a class:'Leaf' or class:'Decision_Node'\n",
    "    It is the key in recursive definition to believe that the function already exists. \n",
    "    \"\"\"\n",
    "    gain, question = find_best_question(samples_train)\n",
    "    if gain == 0:\n",
    "        return Leaf(samples_train)\n",
    "    true_samples_train, false_samples_train = partition(samples_train, question)\n",
    "    true_branch = build_tree(true_samples_train)\n",
    "    false_branch = build_tree(false_samples_train)\n",
    "    return Decision_Node(question, true_branch, false_branch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "sized-colombia",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tree(node, spacing=\"\"):\n",
    "    \"Again, recursive definition\"\n",
    "    # Base case: we've reached a leaf\n",
    "    if isinstance(node, Leaf):\n",
    "        print(spacing + \"Predict\", node.predictions)\n",
    "        return\n",
    "\n",
    "    # Print the question at this node\n",
    "    print (spacing + str(node.question))\n",
    "\n",
    "    # Call this function recursively on the true node\n",
    "    print (spacing + '--> True:')\n",
    "    print_tree(node.true_node, spacing + \"  \")\n",
    "\n",
    "    # Call this function recursively on the false node\n",
    "    print (spacing + '--> False:')\n",
    "    print_tree(node.false_node, spacing + \"  \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "trying-planet",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(sample, tree):\n",
    "    \"\"\"Recursive definition\"\"\"\n",
    "    if isinstance(tree, Leaf):\n",
    "        #print(tree)\n",
    "        return tree.predictions\n",
    "    #print(tree.question)\n",
    "    if tree.question.test(sample):\n",
    "        #print('True')\n",
    "        return classify(sample, tree.true_node)\n",
    "    else:\n",
    "        #print('False')\n",
    "        return classify(sample, tree.false_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "burning-trustee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "#Load the tree calibrated and saved before\n",
    "with open('./my_tree.pkl', 'rb') as f:\n",
    "    my_tree = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "detected-memory",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6h 57min 22s, sys: 49.5 s, total: 6h 58min 11s\n",
      "Wall time: 6h 58min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "######This took > 6 hours to me\n",
    "#my_tree = build_tree(z_train)\n",
    "\n",
    "#####Save calibrated tree as a pickle\n",
    "#with open('./my_tree.pkl', 'wb') as f:\n",
    "#    pickle.dump(my_tree, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "automated-bermuda",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = []\n",
    "for index in range(len(z_test)):\n",
    "    prediction = classify(z_test[index], my_tree)\n",
    "    if str(z_test[index][-1]) not in prediction:\n",
    "        result = False\n",
    "    else:\n",
    "        result = True\n",
    "        for lbl in prediction:\n",
    "            result = result and prediction[str(z_test[index][-1])] >= prediction[lbl]\n",
    "    matches.append(result)    \n",
    "\n",
    "correct = matches.count(True)\n",
    "incorrect = matches.count(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "furnished-proposal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct 8765\n",
      "incorrect 1235\n"
     ]
    }
   ],
   "source": [
    "print('correct', correct)\n",
    "print('incorrect', incorrect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "established-questionnaire",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
